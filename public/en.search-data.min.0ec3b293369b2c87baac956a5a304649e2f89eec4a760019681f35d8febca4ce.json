[{"id":0,"href":"/cisq-maturity/","title":"Index","section":"acje.github.io","content":"Maturity levels in the CISQ security model# A good place to start: CISQ security model v1.0, Maturity level 2 simplified Introducing the model# The Composing Information Security Qualities (CISQ) model is created by combining insights and definitions from the CIA triad, Parkerian Hexad, and STRIDE threat model. The result is a model of four primary security qualities and eleven composed security qualities. Each security quality has a corresponding threat category inspired by the STRIDE threat model. You can read more about prior work on the model here: CISQ-Model of security qualities. Please note that prior work on this model may differ somewhat from this version, as we have adopted more familiar terms for qualities and threats.\nThe CISQ model describes security qualities: positive, naturally emerging qualities we want to preserve in information objects or in the information and behavior of information systems. The CISQ model does not describe systemic qualities that emerge in the relationships between components or within systems, nor does it deal with human-made concepts like legal, ethical, or societal issues. This is why the simplified view of the CISQ model can also be flanked by these two distinct concepts, as shown below.\nTogether with related perspectives, this is a useful representation and starting point for most teams managing information systems. The higher maturity levels are meant for security professionals and infrastructure or platform teams focusing on a deeper understanding of their security posture.\nCISQ security model v1.0, Maturity level 2, simplified overview The CISQ security model can be a bit daunting at first. To make the model more approachable, this document presents a step-by-step maturity model, starting with the four primary qualities and then building on them in a systematic manner.\nModel concept “behavior”# Throughout this model, the phrase “information and behavior” is central. Behavior here refers to any state transitions and observable actions in an information system. The significance is that the model does not limit itself only to information; it also applies to system behavior, such as replying to a message, reading a sensor, or using an actuator.\nModel concept “composition”# Nature’s order is the foundation of our understanding\nA key concept in Composing Information Security Qualities (CISQ) is composition. The four primary security qualities (Availability, Integrity, Control, Authenticity) are composed to create new qualities. All 15 possible compositions are included in the model, the 16th variant the empty set, is excluded. The purpose is to achieve both completeness and non-overlapping concepts. However, this has not yet been formally proven.\nExample: Non-repudiation = Control ⊕ Integrity ⊕ Authenticity.\nHow to use the model# The CISQ model structures the vocabulary of security qualities. These are qualities we want to protect when working with information systems. When performing a risk assessment, as mandated by ISO/IEC 27005, the CISQ model may help when establishing the context and identifying risks. If you use threat modeling to identify risks, CISQ can replace or enhance the STRIDE model.\nMaturity level one# At the first level, the four primary qualities are evaluated in the context of the system. These qualities are important to evaluate for any system, and they form the foundation for all the other security concepts at any maturity level. Note that we refer to the control quality here—borrowed from the Parkerian Hexad—not to be confused with security controls.\nMaturity level one of the CISQ security model The four primary security qualities# Availability – Timely access to information and behavior\nAvailability ensures users and systems can access information and execute required behavior when needed, despite failures, demand spikes, or maintenance. It emphasizes capacity, resilience, and graceful degradation by keeping services responsive under stress and recovering quickly when components fail. Strong availability practices combine demand forecasting and capacity planning, health checks and monitoring, redundancy and failover, load balancing and backpressure, rate limiting and circuit breakers, retry/backoff and queuing, and disaster recovery/business continuity. By preserving availability, teams minimize downtime, sustain essential operations, and maintain user trust.\nCorresponding threat category: Denial of service — disruption or resource exhaustion preventing timely access\nTypical security controls: Redundancy, capacity planning, load balancing\nIntegrity – Preserving correctness and completeness of information and behavior\nIntegrity ensures information and system behavior remain correct, complete, and unaltered from their intended state across storage, transmission, and execution. It focuses on preventing, detecting, and recovering from unauthorized or accidental changes by maintaining invariants and verifying inputs, states, and outputs. Strong integrity practices combine validation and normalization, cryptographic hashes and signatures, transactional guarantees and idempotency, and separation of duties to reduce the chance and impact of tampering. By preserving integrity, teams can trust results, reason about changes, and safely automate decisions and actions.\nCorresponding threat category: Tampering — unauthorized modification compromising correctness or completeness\nTypical security controls: Input validation, hashing, session management, separation of duties\nControl – Power to physically or logically influence information and behavior\nCISQ’s primary control security quality mirrors \u0026ldquo;Possession or Control\u0026rdquo; in the Parkerian Hexad. At its core, the control security quality is all about agency. It concerns the extent to which someone or something can influence an information system. This quality is also special in that it does not apply to widely dispersed information objects and, as such, creates a dichotomy in the CISQ model, with information objects not under exclusive control on one side, and information systems on the other. In modern information systems, control is often shared among other teams and organizations that together exert exclusive control. Typical situations include cloud hosting or smartphones, where manufacturers, hosting providers, operators, and users all have some degree of influence on the systems. Effectively managing control prevents unauthorized manipulation and limits the blast radius when barriers fail.\nCorresponding threat category: Elevation of privilege — unauthorized gain of permissions enabling control, break‑glass workflows\nTypical security controls: Principle of least privilege, patch management, logging and auditing, secure enclaves\nAuthenticity – Information and behavior originate from their purported source\nAuthenticity ensures information and system behavior truly originate from the claimed source and remain bound to that identity across creation, transmission, and execution. It focuses on identity proofing and binding, mutual verification, and provenance, resisting impersonation, spoofing, and forged artifacts. Strong authenticity practices combine a robust identity lifecycle (enrollment, proofing, rotation, revocation), secure channels and token binding, and tamper‑evident logs to establish source and lineage. By preserving authenticity, teams can trust who or what produced actions and data, enabling accountable automation and safe delegation.\nCorresponding threat category: Spoofing — impersonation of identities or sources\nTypical security controls: Multi-factor authentication (MFA), signatures, certificate management and pinning, mutual transport layer security (mTLS)\nMaturity level two# At maturity level two, we introduce some common higher-order qualities that are composed of the control quality and two of the other three primary qualities from maturity level one.\nMaturity level two of the CISQ security model Maturity level two is also represented in the simplified view.\nThe CISQ security model has a base view covering all maturity levels and a simplified overview Utility – Ability to maintain information and behavior\nUtility emphasizes maintainability, operability, and evolvability over time, favoring semantic stability, backward compatibility, and maintainable interfaces.\nCorresponding threat category: Information contortion — distortion or incompatibility reducing ability to maintain or use\nTypical security controls: API management, semantic versioning, type checks, independently deployable components\nConfidentiality – Access to information and behavior is limited exclusively to authorized entities\nCorresponding threat category: Information disclosure — unauthorized exposure of information or behavior\nTypical security controls: Encryption, access control lists (ACLs), data loss prevention (DLP), data classification policies\nNon-repudiation – Assurance of the correctness, completeness, and origin of information and behavior\nCorresponding threat category: Repudiation — denial of actions or origins\nTypical security controls: Signatures, public key infrastructure (PKI), audit trails and logs, message authentication codes (MACs), digital contracts, hashing, trusted third parties\nMaturity level three# At maturity level three, we introduce more precise definitions of concepts. Increasing your depth of conceptual understanding may help you develop and categorize security controls (not to be confused with the control quality in the CISQ model).\nMaturity level three of the CISQ security model Authorization – Power to grant access to information and behavior\nCorresponding threat category: Broken access control — missing or incorrect checks allow unauthorized actions or data access\nTypical security controls: Policy‑based access control (RBAC/ABAC), centralized policy engines (e.g., OPA), deny‑by‑default and least privilege, resource‑scoped checks at API/service/data layers, tenant isolation, permission boundaries/guardrails, entitlement reviews and audited authorization decisions\nDurability – Ability to withstand degradation of the integrity of information and behavior\nCorresponding threat category: Data corruption — integrity degradation of stored or transmitted data\nTypical security controls: Automatic rebuilding, forward error correction (FEC), error correction codes (ECC)\nCredibility – Ability to verify information and behavior\nCorresponding threat category: Misinformation — deceptive or misleading content undermining verification\nTypical security controls: Cryptographic signatures, certificate pinning, PKI validation, trusted timestamping, source verification policies, tamper-evident logging, content validation workflows, reputation/trust lists\nCertifiability – Ability to prove the validity of information and behavior\nCorresponding threat category: Invalid attestation — unverifiable or untrusted proofs of validity\nTypical security controls: Third‑party audits and certifications (ISO, SOC 2), attestation frameworks (TPM/TEE remote attestation), formal verification/conformance testing, reproducible builds, SBOMs and supply chain attestations, notarization/trusted registries\nAssurance – Ability to positively confirm information and behavior\nCorresponding threat category: Unverified behavior — insufficient evidence to confirm claims or outcomes\nTypical security controls: Conformance and acceptance tests, runtime assertions, SLO/SLA monitoring and health checks\nTraceability – Ability to discover where and how information and behavior were produced\nCorresponding threat category: Obfuscation — concealed provenance or tampered production trails\nTypical security controls: Structured logging with correlation IDs, distributed tracing (OpenTelemetry), append‑only/immutable logs, cryptographic log signing, data lineage catalogs, version control and change history, chain‑of‑custody procedures\nUsefulness – Ability to work with the format of information and behavior\nUsefulness focuses on representational compatibility and format‑level interoperability, emphasizing schemas, canonicalization, and robust parsing.\nCorresponding threat category: Data misformatting — incompatible, ambiguous, or malformed representations\nTypical security controls: Schema registries and data dictionaries, strict typing and validation, canonical data models, format normalization and conversion, API versioning, compatibility testing\nMaturity level four# At level four, we define the sole quality that composes all four primary qualities. Reliability = Availability ⊕ Integrity ⊕ Control ⊕ Authenticity. The most prominent systems that create technical guarantees for all four qualities are smart contracts running on blockchains. However, not all qualities need to be backed by technical guarantees. Many organizations deliver very good reliability as a combination of technical, process, and organizational measures. Financial institutions are typical examples of such systems, where all aspects come together to create a level of trust such that customers are willing to hand over control of their assets to these organizations.\nAs information systems continue to permeate into increasingly essential processes, the need to balance technological, organizational and process mechanisms increases. This document structures how to reduce the most significant risk mainly using technical means because this is in reality automation of risk mitigation and avoidance. Automation is generally cheaper and faster than the alternatives which are organizational and process mechanisms. However to manage the risk treatment of rare and niche risks we typically do not initiate with automation, rather we use process or organizational structure.\nUsing process for risk mitigation and avoidance# Keeping humans in the loop is a major way of compensating with process. This could mean having humans evaluate the decision made by a system to check if it aligns with desired business outcomes such as fraud detection, application approval or rejection, state sanctioned revocation of private or business privileges including mandating use of state sanctioned violence to detain personnel.\nUsing organization for risk mitigation and avoidance# Organizations mitigate risk through structure, clear decision rights, and accountable ownership. These mechanisms complement technical and process controls by establishing guardrails for change, prioritizing remediation, and defining escalation paths when constraints (legal, regulatory, budgetary, human) limit automation.\nEffective organizational control clarifies ownership of information and systems; separates building, risk oversight, and auditing into independent lines of defense; and enforces segregation of duties with dual control and break‑glass procedures. Policies and risk registers make risk appetite explicit and track treatment plans, while incident response and crisis management ensure prepared roles, rotations, playbooks, and communication. Business continuity planning, vendor governance, and supply‑chain assurance reduce concentration risk and ensure recoverability. Data governance assigns stewardship, classification, retention, and privacy impact assessments. Portfolio and budgeting processes fund remediation and resilience via risk‑based prioritization and reduction of operational debt.\nOrganizational controls bound blast radius, enable predictable escalation, and sustain reliability at maturity level four—especially for rare or niche risks and constraints that cannot be fully automated.\nMaturity level four of the CISQ security model Reliability – Trustworthy information and behavior\nCorresponding threat category: Dependability loss — systemic failures reducing trust in outcomes\nTypical security controls: Balance technological, organizational or process controls to compensate for weaknesses. Smart contacts, transactional integrity, idempotency, distributed consensus, circuit breakers and retry/backoff, disaster recovery and business continuity plans, chaos engineering\nResources# Download Excalidraw file\nDownload CISQ-simplified-large\nMaturity level, Qualities, Composition, Threat# lvl Quality Composition Threat 1 Availability Availability Denial of service 1 Integrity Integrity Tampering 1 Control Control Elevation of privilege 1 Authenticity Authenticity Spoofing 2 Utility Availability ⊕ Integrity ⊕ Control Information contortion 2 Confidentiality Availability ⊕ Control ⊕ Authenticity Information disclosure 2 Non-repudiation Integrity ⊕ Control ⊕ Authenticity Repudiation 3 Authorization Availability ⊕ Control Broken access control 3 Durability Integrity ⊕ Control Data corruption 3 Credibility Control ⊕ Authenticity Misinformation 3 Certifiability Availability ⊕ Integrity ⊕ Authenticity Invalid attestation 3 Assurance Availability ⊕ Integrity Unverified behavior 3 Traceability Integrity ⊕ Authenticity Obfuscation 3 Usefulness Availability ⊕ Integrity Data misformatting 4 Reliability Availability ⊕ Integrity ⊕ Control ⊕ Authenticity Dependability loss "},{"id":1,"href":"/cisq-model/","title":"Index","section":"acje.github.io","content":"A structured view on information security# The CISQ-model hypothesis# What is the CISQ-model?# The CISQ-model (Composing Information Security Qualities) builds on the hypothesis that there are exactly four basic security qualities. Integrity, Authenticity, Availability and Control. A total of 16 qualities can be composed from these four basic qualities, if we include the “none” quality and the four basic qualities them selves. The most useful subset of the model when dealing with a service is shown below.\nWhy do we need more information security acronyms?# Although this model is much more complicated than the CIA-triad or even the STRIDE threat model, the CISQ-model presents an opportunity to approach information security in a way that can start at low complexity with only the four basic qualities, and then guides the user towards deeper understanding of their own system by introducing or eliminating security qualities. This is done by the composition. If a basic quality is important or seen as irrelevant for the system this insight can be used to guide attention to the higher order qualities composed form the basic qualities. \u0026ldquo;Rather than trying to change the world, change how people see the world. Because when they see the world differently, they behave differently and that will change the world\u0026rdquo; - Rory Sutherland\nThe goal is to create a vocabulary for information security that covers the field of component security qualities as much as possible while minimizing overlap and ambiguity. Non-goals include legal, ethical and societal issues as well as describing system level properties such as defense in depth, resilience, anti-fragility and isolation. A lengthy tale of system level properties may interest you\nFoundations# For information objects the four basic qualities are as follows;\nIf the object is intact it is considered to have the integrity quality If the object has a known origin it is considered to have the authenticity quality If the object can be reached in a timely manner it is considered to have the availability quality If the object is exclusively controlled by an enumerated set of entities it is considered to have the control quality For behavior in an information system, such as a service, we have the same four qualities;\nIf the behavior is intact it is considered to have the integrity quality If the behavior has a known origin it is considered to have the authenticity quality If the behavior can be reached in a timely manner it is considered to have the availability quality If the behavior is exclusively controlled by an enumerated set of entities it is considered to have the control quality Notable remarks# Integrity and authenticity are both considered as discrete and absolute, whereas availability and control are continuous and open-ended. This has important consequences for how we can reason about information security. For instance the control quality will always be subject to “force majure” situations like an asteroid or government agency impacting your service, no mater how well the system is designed. The availability quality can span towards infinite time, hence making absolute guarantees difficult to define. The CISQ-model deliberately use the wording “basic” security quality, as opposed to “atomic” or “axiomatic” because these qualities may very well be broken down even further, just like the atom. This can be trivially shown for availability with the concepts of time, completeness and (network) partitioning in distributed systems all contributing their own aspects of availability. In other words the CISQ-model is more like the composed building blocks of the periodic table and less like the standard model of physics. The model in depth# The CISQ-model uses composition to expand the four basic security qualities (Integrity, Authenticity, Availability, Control) into a total of 16 qualities as shown in the table below.\nVisualizing the composition of four aspects is not easy to get right. This view shows how we can simplify the model by splitting the model into two separate views. One model for systems that are controlled, typically by an organization and the other for public domain objects such as certificates.\nVocabulary of the CISQ-Model# These definitions are a work in progress. two principles are important:\nKeep the definitions as short as possible, which is easier since the overloading of terms are much less than in the CIA-triad. Symmetry between information and behavior across all terms Reliability – Trustworthy information and behavior\nSustainability - Ability to maintain information and behavior\nConfidentiality - Access to information and behavior being exclusively limited to authorized entities\nAuthority - Power to grant access to information and behavior\nAccountability - Assurance of the correctness, completeness and origin of information and behavior\nDurability - Ability to withstand integrity degradation of information and behavior\nCredibility - Verified information and behavior\nControl - Power to physically or logically influence information and behavior\nCertifiability - Ability to prove validity of information and behavior\nUtility - Usefulness of information and behavior\nAssurance - Positive declaration of information and behavior\nAvailability - Timely access to information and behavior\nTraceability - Ability to discover where and how information and behavior was made\nIntegrity - Preserving correctness and completeness of information and behavior\nAuthenticity - Origin of information and behavior is from its purported source\nUnreliability - Not capable of providing security qualities for information and behavior\nOrigin story# The CISQ-model comes with its own origin story. Se if you can spot the evolution from its first stage. A case against the CIA triad\n"},{"id":2,"href":"/ecosystem/","title":"Index","section":"acje.github.io","content":"An Ecosystem for Sovereign Digital Nations# Breaking the chains of digital vassalage by employing political instruments and architectural constraints to reshape the ecosystem that builds our digital infrastructure and services.\nPublished 2026-01-22 An Ecosystem for Sovereign Digital Nations - Part 1 Introduction Updated 2026-02-01 Summary# Infrastructure and essential services increasingly rely on information systems with shared vulnerabilities and inherent brittle design. This cocktail of pervasiveness, commonality and fragility creates conditions of systemic vulnerabilities prone to cascading failures.\nThe aim is to describe an ecosystem that reduces systemic vulnerabilities to an acceptable level for all infrastructure and services. Describing how existing information systems can be sufficiently patched and remodelled to become sufficiently secured is not a goal, in fact it is assumed to be impossible. A real rupture needs to happen, and the old systems will not likely cross the chassm. Still the defeatism that prevails in parts of the IT industry, that we simply can not have inherently secure systems, is equally rejected in this series. It will be asserted that such an ecosystem consists of five principal necessities. By targeting the ecosystem rather than the information systems directly, we create a new situation where systems across all sectors of society benefit. This must be done through politically mandated, verifiable and trusted supply chains, hosting and operations. Further this must be combined with architecture principles that limit blast radius by employing isolation as a defense-in-depth strategy and rigidly enforce least privilege integrations at all levels.\nThe fundamental challenge of increasing the number of inherently insecure and critical systems# Times are changing with new geopolitical rules that appear undefined at the moment. The systems and attitudes that got us here are unlikely to be the ones that will get us through it. For the purpose of this post I will defer the naming of the coming period to the historians. When considering this looming challenge it is important to realize that the adversaries and their capabilities are not the significant source of the problem. The adversary is inevitable. The big problem is our own creation of a target rich environment of critically important systems with common vulnerabilities. There will eventually be an adversary with the means and motivation to use the vulnerabilities against us. The additional risk posed by a nation state adversary is not its ability to penetrate and exploit information systems, but its ability to coordinate with other events. The list of historic attacks exploiting systemic weaknesses are many; Stuxnet, NotPetya, WannaCry, HeartBleed, SolarWinds, Colonial Pipeline operations, Ukraine grid attacks and Salt Typhoon telecom attacks, to name a few famous examples. These kind of attacks will occur with uneven intervals, and the size of these attacks will grow proportionally to the number of available targets, because the size is largely a function of the environment, and less related to the attackers capabilities.\nSelf-organized criticality# Forest fires, avalanches and digital transformation may have one dangerous thing in common: Self-organizing to criticality. The spark that starts a large forest fire is not meaningfully different from the spark that does not. The snowflake that starts a large avalanche is not meaningfully different from those that do not. The meaningful difference is in the combined potential in the environment, not the trigger event. The damage potential has built up over time from dead organic debris or snowflakes landing on top of each other. The trigger is just a statistically inevitable event, releasing the potential. This was described mathematically as “Self-organized criticality” by mathematicians Per Bak, Chao Tang and Kurt Wiesenfeld in 1987.\nWhat I propose here is that forcefully engaging in digital transformation is highly likely to create a similar situation to forest fires and avalanches. This happens as we deploy an ever increasing number of inherently insecure systems across all critical sectors in our societies. Thereby creating a situation where a single mode of attack or shared vulnerability may trigger a ripple effect through our society. This could end up tearing down critical infrastructure and services like energy, communication, healthcare, finance, transportation, and water supply.\nTo counter this scenario I propose a strategic application of political instruments and architectural constraints on the ecosystem that produces these systems. The following outlines the three political and two architectural pillars of an ecosystem for creation of meaningfully more secure information systems. These systems will not have absolutely zero risk, but they should reduce the risk to such a level that the risk is acceptable for use across all critical infrastructure and services.\nCritical and non-critical information systems are largely built the same# Critical information system typically has more rigorous design, more controls are implemented and documented and more layers of isolation are typically implemented. Yet they tend to be built using the same services and components as non-critical systems. When the functional needs are the same, there is rarely any gain in using lower grade software components or services in non-critical systems. The hardware may vary somewhat more in quantity and sometimes also in quality, but most systems attributes are software defined these days.\nA hierarchy of security aspects# Where we intervene is of importance for how far we can reach. A simplified model for how to understand how information systems are created, managed and cause security outcomes, may be helpful. The ecosystem consists of all the available services, components and trained personnel that goes into creating information systems. The systems themselves are created from what is available at their time of creation and during their period of maintenance. These information systems cause security events such as unexpected downtime due to internal, natural or adversarial actions on the system. Dependent on the systems ability to withstand these actions and the organizations ability plan for and react to these events, we get security outcomes. In this post we will look at actions we can take at the ecosystem level to create a situation where all new and actively maintained systems can be made to produce meaningfully better security outcomes. When we intervene at this level we are more likely to maximize impact compared to intervening at lower levels of this model.\nEcosystem -\u0026gt; information systems -\u0026gt; security events -\u0026gt; security outcomes\nIn this post we are going to look into how we can understand and modify the ecosystem that functions as the basis for how information systems are created. Three political and two architectural necessities have been identified in an ecosystem that will produce meaningfully more secure information systems, suitable for the pervasive digitalization that finds its way into most sectors of critical infrastructure and services.\nNecessities of an ecosystem that produce inherently secure systems# To highlight structure for the different audiences the necessities has been categorized into two different areas. The political necessities are about aspects of the ecosystem that typically will need multi-national political effort to achieve. The architectural necessities may also need political help to advance at reasonable pace, but caution need to be used when mandating their use because technological breakthroughs may change how architecture should be shaped.\nThe asserted principal necessities for an ecosystem that will create meaningfully more secure information systems are as follows.\nPrincipal political necessities# Trusted supply chain Trusted hosting Trusted operations Principal architectural necessities# Maximally isolated components of least capability Least privilege interfaces Principal stewardship necessities# TODO Upcoming parts in this series# In the next parts I will break down the political and architectural necessities in more detail, define scope, identify inherent challenges, and outline solutions and \u0026ldquo;near enemy\u0026rdquo; non-solutions.\nTODO Next: An Ecosystem for Secure Information Systems - Part 2 Political means\nOther posts in category Systems and security# Maturity levels in the CISQ security model\nLiberal democracies needs a new compute stack. Part 1 (Substack)\nLiberal democracies needs a new compute stack. Part 2 (Substack)\nLiberal democracies needs a new compute stack. Part 3 (Substack)\nLiberal democracies needs a new compute stack. Part 4 (Substack)\n"},{"id":3,"href":"/scaled_agile/post/","title":"Post","section":"Scaled_agiles","content":"Scaling Agile# These are my notes on how an organization transformed from hardly being able to run a handful of digitalization projects in parallel and only creating value from them sporadically, into a fast-moving agile organization. I have observed this type of transition twice in the role of architect in two different organizations, both with tens of projects and later, tens of teams running in parallel. The first transition was targeting the SAFe-Framework. The second transition was a much more deliberate and tailored approach. The deliberate and tailored transition will be the main topic of these notes, but I might reference the first transition explicitly where appropriate.\nSummary# Obtaining massive improvements in speed, domain knowledge and short-term value creation is very doable. Following the practices from \u0026ldquo;Accelerate\u0026rdquo; and implement stream aligned teams and platform teams from \u0026ldquo;Team topologies\u0026rdquo; are well established techniques by now. Then make sure your teams gets a clear \u0026ldquo;mission\u0026rdquo; limited to a reasonably sized business domain, while protecting them from strong internal forces that will want to deliver change tickets to the teams.\nThe lessons discussed here are more subtle and deals with aspects that arise from the success of scaling agile organizations.\nFirst lesson - Speed is surprisingly a substitute for direction, but speed alone doesn´t scale well. Second lesson - Managing the second order effects of success. Producing new assets creates risks and opportunities hiding or missing in the structure of your implementations. Third lesson/hypothesis - Within the concept of \u0026ldquo;mission command\u0026rdquo; use the backbrief to empower the relation between stakeholders and product teams. Work in progress# For the rest of this post I will proceed to explain:\nSetting the context# What we actually did to create a productive digitalization org. The humble beginnings; transition from projects to teams secures continuity in knowledge about the business domain and the produced asset, often referred to as the product. Splitting stream aligned teams and platform teams to leverage scale. This failed at first because the applications were too tightly coupled to the platform and this also caused the platform not to evolve into a capability with sufficiently self-service. The result was that we largely ended up with a 1:1 of platform and application effort. A redesign of the underlying application architecture and platform was needed. The second attempt yielded a almost fully self service platform and we even put some effort into not depending too deeply on custom cloud features. Architecture is not the scope here, but we largely created separate sandboxes for each system, relying heavily on self-hosted NATS on cloud VMs to create a communication mesh that also can persist streams of data. Other cloud services are freely chosen by the teams but they are incentivized to use containers and postgres-as-a-service. Run your own VM if you need something bespoke. The result is more like a 1:10 effort in platform and application, allowing us to scale up stream aligned teams while spending much less on creating and maintaining a platform. Leadership and scale; We eventually got to working at the transition from both bottom and top, transforming the IT department first and the rest of the 1300 person organization is about to follow.There was however significant upfront effort over multiple years to create continuous deployment, container based runtimes, git as a service, team vs project awareness and so forth. When the two first teams were established a lot of the uncertainty was eliminated. We could do this! Luckily we had massive change of mindset in large parts og management around this time. Teams were to become the new normal. Projects had proven time and again that they delivered late or not at all and when they delivered there was almost instantly the need for a new project to fix everything that the first one got wrong. Observations# First lesson - Speed is surprisingly a substitute for direction, but it doesn´t scale well alone. Bees and discovery: serendipity, 20% ignores plan/bee-dance Some alignment scales speed. Turning alignment to 0 or 11 creates traps of local optimization Second lesson - Managing the second order effects of success. Producing new assets creates risks and opportunities hiding or missing in the structure of your implementations. Kent Beck — behavior and structure Risks as second order effects of successfully creating new assets Managing Opportunities with Architecture\nArchitecture is one of those things that has a tendency to get \u0026ldquo;thrown out with the bath water\u0026rdquo; when organizations move to agile methodologies.\nImprovements# Places to innovate\nThe Art of Action — directed opportunism Operational gaps Three Critical Gaps\nHierarchy of cascading intent\nInstitute backbrief\nAlignment and autonomy\nSee Alignment and autonomy for more details (self-reference)\nManaging costs of transition\nOrganizational costs Personal costs "}]